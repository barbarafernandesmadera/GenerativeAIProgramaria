{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ythWxcU2iQcx"
      },
      "source": [
        "# Primeiros passos na API do Gemini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBzUTizqiS9J"
      },
      "source": [
        "Esse √© o c√≥digo que desenvolvemos juntos durante a aula da Sprint da Programaria! Neste primeiro passo, vamos nos conectar √† API da Google (Gemini) e gerar uma hist√≥ria de um unic√≥rnio no universo de Game of Thrones ü¶Ñüêâ.\n",
        "\n",
        "Ao longo do processo, tamb√©m vamos explorar alguns par√¢metros da IA para entender como eles influenciam na cria√ß√£o da hist√≥ria. Bora testar e se surpreender com as possibilidades?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAGvBO9TxVz3"
      },
      "source": [
        "# Instalando a biblioteca do Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pCjVy-_d12LR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRPTHAljxY71"
      },
      "source": [
        "# Importanto as bibliotecas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3uhK5QEI3GFd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instalado com sucesso!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\barbara.fernandes\\Documents\\codigoGE\\IAGenerativa\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import userdata-caso voc√™ use no google colab\n",
        "import google.generativeai as genai\n",
        "print(\"Instalado com sucesso!\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Carrega o .env\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chave Gemini carregada: AIzaSyDp...\n"
          ]
        }
      ],
      "source": [
        "# Pega a chave secreta da Gemini\n",
        "api_key = os.getenv(\"SECRET_KEY\")\n",
        "print(\"Chave Gemini carregada:\", api_key[:8] + \"...\" if api_key else \"N√£o carregada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configura o cliente Gemini\n",
        "genai.configure(api_key=api_key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seleciona o modelo (ex: Gemini 1.5 Flash)\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75uvPjc_xhmA"
      },
      "source": [
        "# Verificando modelos de IA generativa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH8G7xFDxOIS"
      },
      "source": [
        "Verificando quais modelos de IA Generativa est√£o dispon√≠veis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "BJybPKBD3vNK",
        "outputId": "7a11c9a2-dcfe-4906-8763-8ce412893a24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-2.5-pro-exp-03-25\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-04-17\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-preview-04-17-thinking\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX6kz7Xexnv6"
      },
      "source": [
        "# Gera√ß√£o de Conte√∫do com Gemini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k-oZMYeEWnL"
      },
      "source": [
        "Agora chegamos no melhor momento de todos, testar a capacidade criativa das IAs Generativas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Faz uma pergunta\n",
        "response = model.generate_content(\"Escreva uma hist√≥ria em uma frase sobre um gato chamado Alan da cor frajola no mundo de Game of Throne\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alan, um gato frajola de olhos esmeralda, se esquivou de flechas e intrigas em Westeros, subindo na hierarquia do poder felino at√© se tornar o Mestre dos Murros, aconselhando secretamente os reis e rainhas com seus miaus enigm√°ticos.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mostra a resposta\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fSmhlGMD4si"
      },
      "source": [
        "Agora vamos ajustar e refirnar alguns pontos da IA usando os par√¢metros que aprendemos na aula"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "_X0RTh_94dgG",
        "outputId": "7b0b3e22-d435-46b1-85dd-78752c2f506d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alan, um gato torto, com pelos mal cuidados e olhos brilhantes, pulou pelos campos sangrentos de Westeros, enquanto ele ca√ßava ratos em meio aos conflitos das grandes casas e ocasionalmente acidentalmente sentado no ombro de um rei.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = model.generate_content(\"Escreva uma hist√≥ria em uma frase sobre um gato chamado Alan da pelagem frajola no mundo de game of thrones\",\n",
        "                                  generation_config={\"temperature\": 1.5,\"max_output_tokens\": 100},\n",
        "                                  safety_settings=[{\"category\":'HARM_CATEGORY_HATE_SPEECH','threshold':3}])\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NwsrQYoD-Gd"
      },
      "source": [
        "Notaram a diferen√ßa entre essa sa√≠da e a anterior? Isso mostra como, ao ajustarmos os par√¢metros da IA, conseguimos obter respostas diferentes. Cada ajuste pode influenciar diretamente o comportamento do modelo."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
